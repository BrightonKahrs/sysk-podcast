{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff You Should Know Podcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Covers\n",
    "0. Import dependencies\n",
    "1. Retrieving xml from sysk feed\n",
    "2. Parsing xml and transforming into json\n",
    "3. Fetching mp3 files for episodes\n",
    "4. Transcribing mp3 using whisper tiny model\n",
    "5. Chunking and embedding transcripts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will heavily rely on Whisper and Langchain to accomplish our objectives. These technologies will enable us to generate high-quality, coherent, and informative text by leveraging the vast knowledge and language understanding capabilities of the models. Remember to run this section for module import if starting from any other section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "import requests\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import xmltodict\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving xml from sysk feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to retrieve the latest sysk rss feed. This feed contains information from the podcast, such as episode descriptions and links to the mp3 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for rss_feed if not exists\n",
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "save_folder = os.path.join(parent_directory, 'rss_feed')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Request rss file\n",
    "podcast_url = 'https://omnycontent.com/d/playlist/e73c998e-6e60-432f-8610-ae210140c5b1/A91018A4-EA4F-4130-BF55-AE270180C327/44710ECC-10BB-48D1-93C7-AE270180C33E/podcast.rss'\n",
    "response = requests.get(podcast_url)\n",
    "\n",
    "# Save rss file to new directory\n",
    "save_file_path = os.path.join(save_folder, 'sysk_podcast.rss')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(save_file_path, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parsing xml and transforming into json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to clean things up, let's fetch the useful information from xml rss feed and transform that into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Retrieve the newly created file. I repeat myself here in case user starts fresh from section 2\n",
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "load_file_path = os.path.join(parent_directory, 'rss_feed', 'sysk_podcast.rss')\n",
    "with open(load_file_path, 'r', errors='ignore') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Create folder for episode information\n",
    "save_folder = os.path.join(parent_directory, 'episode_info')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Parse xml into a dict\n",
    "xml_dict = xmltodict.parse(content)\n",
    "\n",
    "# Get list of items (aka podcast episodes)\n",
    "items = xml_dict['rss']['channel']['item']\n",
    "\n",
    "# Important step to only take 10 shorter episodes for practice, comment out to run full list\n",
    "i = 0\n",
    "items_temp = []\n",
    "for item in items:\n",
    "    if i == 10:\n",
    "        break\n",
    "    if 'Short Stuff' in item['title']:\n",
    "        items_temp.append(item)\n",
    "        i += 1\n",
    "items = items_temp\n",
    "\n",
    "# Loop through items in xml dict and dump into new folder as json\n",
    "for item in items:\n",
    "    episode_info = {\n",
    "        'title': item['title'],\n",
    "        'guid': item['guid']['#text'],\n",
    "        'publish_date': item['pubDate'],\n",
    "        'mp3_path': item['enclosure']['@url']\n",
    "    }\n",
    "\n",
    "    save_file_path = os.path.join(save_folder, item['guid']['#text'] + '.json')\n",
    "    with open(save_file_path, 'w') as file:\n",
    "        json.dump(episode_info, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fetching mp3 files for episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the mp3_path parsed from the xml rss feed (then persisted into json) to download the associated mp3 into another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve episode_info\n",
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "load_folder = os.path.join(parent_directory, 'episode_info')\n",
    "episode_info_dir = os.listdir(load_folder)\n",
    "\n",
    "# Create folder for mp3 audio if it does not already exist\n",
    "save_folder = os.path.join(parent_directory, 'audio')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Open up each file in episode_info folder, download mp3 files to new audio folder, name each mp3 with the associated episode guid\n",
    "for episode in episode_info_dir:\n",
    "    file_path = os.path.join(load_folder, episode)\n",
    "\n",
    "    with open(file_path, 'r') as episode_info:\n",
    "        data = json.load(episode_info)\n",
    "        mp3_path = data.get('mp3_path')\n",
    "        guid = data.get('guid')\n",
    "        response = requests.get(mp3_path)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            save_file_path = os.path.join(save_folder, guid + '.mp3')\n",
    "            with open(save_file_path, \"wb\") as file:\n",
    "                file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create whisper model \"tiny\"\n",
    "model = whisper.load_model(\"tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brigh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# Get necessary paths\n",
    "audio_path = os.path.join(parent_directory, 'audio')\n",
    "episode_info_path = os.path.join(parent_directory, 'episode_info')\n",
    "\n",
    "# Loop through episode_info folder, lookup audio from guid, transcribe using whisper, write transcription back into episode_info json\n",
    "for episode in episode_info_dir:\n",
    "    file_path = os.path.join(episode_info_path, episode)\n",
    "\n",
    "    with open(file_path, 'r') as episode_info:\n",
    "        data = json.load(episode_info)\n",
    "        guid = data.get('guid')\n",
    "        audio_file_path = os.path.join(audio_path, guid + '.mp3')\n",
    "\n",
    "        transcription = model.transcribe(audio_file_path)\n",
    "        data['transcription'] = transcription['text']\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
